# Jupyter notebook with PySpark for interactive Iceberg table queries
services:
  spark-notebook:
    image: jupyter/pyspark-notebook:spark-3.4.1  # Locked to Spark 3.4.1 (Scala 2.12)
    container_name: spark-notebook
    environment:
      JUPYTER_ENABLE_LAB: "yes"  # Enable JupyterLab interface
    ports:
      - "8888:8888"  # Jupyter notebook interface
      - "4040:4040"  # Spark UI for monitoring jobs
    volumes:
      - ./workspace/notebooks:/home/jovyan/work  # Mount local notebooks to Jupyter's work directory
      - ./workspace/data:/home/jovyan/data       # Mount local data files
      - warehouse_storage:/warehouse             # Shared volume for Iceberg data
    networks:
      - dasnet  # Connect to same network as Polaris and MinIO
    restart: unless-stopped

# Docker network - connects to existing dasnet created by docker-compose.yml
networks:
  dasnet:
    driver: bridge
    name: dasnet
    external: true  # Must already exist

# Shared volume for Iceberg warehouse data
volumes:
  warehouse_storage:
    name: warehouse_storage
    external: true  # Must be created manually: docker volume create warehouse_storage